{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "adhoctableretrieval.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hwj__5TdFsTe",
        "colab_type": "text"
      },
      "source": [
        "# This is an extra notebook used for the semantic matching to be able to process large word embedding files since this could not be done locally. This notebook is ran on google colab.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtI4hT1XF6fW",
        "colab_type": "code",
        "outputId": "512de5e0-a166-40f4-d851-ad37fb110e5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "model = api.load(\"glove-wiki-gigaword-300\")\n",
        "filename = \"results_glove_300\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYauZMnj-Juf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from joblib import load\n",
        "\n",
        "def projectTerms(gensim_model, terms):\n",
        "    return [projectSubTerms(gensim_model,term_list) for term_list in terms]\n",
        "\n",
        "def projectSubTerms(gensim_model, terms):\n",
        "    return [gensim_model[term] for term in terms if term in gensim_model]          \n",
        "\n",
        "query_terms = load('query_tokens.joblib')\n",
        "semantic_query_terms = projectTerms(model,query_terms)\n",
        "\n",
        "table_terms = load('table_tokens_better.joblib')\n",
        "table_terms_unique = [list(set(termslist)) for termslist in table_terms]\n",
        "semantic_table_terms = projectTerms(model,table_terms_unique)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trUK93CxWPT6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.summarization.bm25 import BM25\n",
        "\n",
        "baseline = BM25(table_terms)\n",
        "average_idf = sum(map(lambda k: float(baseline.idf[k]), baseline.idf.keys())) / len(baseline.idf.keys())\n",
        "\n",
        "raw = pd.read_csv(r'qrels.txt', delimiter='\\t', names=[\"query-id\", \"zeros\", \"table-id\", \"rel\"])\n",
        "\n",
        "res = {\n",
        "    'query-id': list(),\n",
        "    'q0': list(),\n",
        "    'document-id': list(),\n",
        "    'rank': list(),\n",
        "    'score': list(),\n",
        "    'name': list()\n",
        "}\n",
        "\n",
        "for index, row in raw.iterrows():\n",
        "    res['query-id'].append(row[\"query-id\"])\n",
        "    res['q0'].append('Q0')\n",
        "    res['document-id'].append(row[\"table-id\"])\n",
        "    res['rank'].append(0)\n",
        "    res['score'].append(baseline.get_score(query_terms[row[0] - 1], index, average_idf))\n",
        "    res['name'].append('STANDARD')\n",
        "\n",
        "df_res = pd.DataFrame.from_dict(res)\n",
        "\n",
        "df_res.to_csv('bm25.txt', sep=' ', index=False, header=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfzXyNLc_PLE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import TfidfModel\n",
        "from gensim.corpora import Dictionary\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "\n",
        "table_terms2 = load('table_tokens_better.joblib')\n",
        "table_sents = [' '.join(terms) for terms in table_terms2]\n",
        "\n",
        "cv = CountVectorizer()\n",
        "\n",
        "# convert text data into term-frequency matrix\n",
        "data = cv.fit_transform(table_sents)\n",
        "\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "\n",
        "# convert term-frequency matrix into tf-idf\n",
        "tfidf_matrix = tfidf_transformer.fit_transform(data)\n",
        "\n",
        "# create dictionary to find a tfidf word each word\n",
        "word2tfidf = dict(zip(cv.get_feature_names(), tfidf_transformer.idf_))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPhi8NOsFr2Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy import spatial\n",
        "import numpy as np\n",
        "\n",
        "def cos_early_sim(table_terms, table_tokens, query_terms, query_tokens):\n",
        "    query_terms_tfidf = [word2tfidf[query_token] if query_token in word2tfidf else 1 for query_token in query_tokens]\n",
        "    \n",
        "    table_terms_tfidf = [word2tfidf[table_token] if table_token in word2tfidf else 1 for table_token in table_tokens]\n",
        "\n",
        "    query_terms_weighted = [np.multiply(q_vec, q_weight) for (q_vec, q_weight) in zip(query_terms,query_terms_tfidf)]\n",
        "    table_terms_weighted = [np.multiply(t_vec, t_weight) for (t_vec, t_weight) in zip(table_terms,table_terms_tfidf)]\n",
        "\n",
        "    query_sum = np.sum(query_terms_weighted, axis = 0)\n",
        "    table_sum = np.sum(table_terms_weighted, axis = 0)\n",
        "    \n",
        "    return  (1 - (spatial.distance.cosine(query_sum,table_sum)))\n",
        "\n",
        "\n",
        "def late_fusion(table_terms, query_terms):\n",
        "    combs = []\n",
        "    for table_term in table_terms:\n",
        "        for query_term in query_terms:\n",
        "            cossim = 1 - (spatial.distance.cosine(table_term, query_term))\n",
        "            combs.append(cossim)\n",
        "    return combs\n",
        "                             \n",
        "def cos_late_max_sim(table_terms, query_terms):\n",
        "    combs = late_fusion(table_terms, query_terms)\n",
        "    return max(combs) if len(combs) > 0 else 0 \n",
        "                             \n",
        "def cos_late_sum_sim(table_terms, query_terms):\n",
        "    combs = late_fusion(table_terms, query_terms)\n",
        "    return sum(combs) if len(combs) > 0 else 0 \n",
        "                             \n",
        "def cos_late_avg_sim(table_terms, query_terms):\n",
        "    combs = late_fusion(table_terms, query_terms)\n",
        "    return np.mean(combs) if len(combs) > 0 else 0 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uQxSd1uxthg",
        "colab_type": "text"
      },
      "source": [
        "# Late average"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fij5amQyHHeo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "raw = pd.read_csv(r'qrels.txt', delimiter='\\t', names=[\"query-id\", \"zeros\", \"table-id\", \"rel\"])\n",
        "\n",
        "res = {\n",
        "    'query-id': list(),\n",
        "    'q0': list(),\n",
        "    'document-id': list(),\n",
        "    'rank': list(),\n",
        "    'score': list(),\n",
        "    'name': list()\n",
        "}\n",
        "\n",
        "for index, row in raw.iterrows():\n",
        "    res['query-id'].append(row[\"query-id\"])\n",
        "    res['q0'].append('Q0')\n",
        "    res['document-id'].append(row[\"table-id\"])\n",
        "    res['rank'].append(0)\n",
        "    res['score'].append(cos_late_avg_sim(semantic_table_terms[index], semantic_query_terms[row[\"query-id\"] - 1]))\n",
        "    res['name'].append('STANDARD')\n",
        "\n",
        "df_res = pd.DataFrame.from_dict(res)\n",
        "\n",
        "df_res.to_csv(filename + '_late_avg.txt', sep=' ', index=False, header=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybu52RmOxyfg",
        "colab_type": "text"
      },
      "source": [
        "# Late sum\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPYFa5b5xswL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "raw = pd.read_csv(r'qrels.txt', delimiter='\\t', names=[\"query-id\", \"zeros\", \"table-id\", \"rel\"])\n",
        "\n",
        "res = {\n",
        "    'query-id': list(),\n",
        "    'q0': list(),\n",
        "    'document-id': list(),\n",
        "    'rank': list(),\n",
        "    'score': list(),\n",
        "    'name': list()\n",
        "}\n",
        "\n",
        "for index, row in raw.iterrows():\n",
        "    res['query-id'].append(row[\"query-id\"])\n",
        "    res['q0'].append('Q0')\n",
        "    res['document-id'].append(row[\"table-id\"])\n",
        "    res['rank'].append(0)\n",
        "    res['score'].append(cos_late_sum_sim(semantic_table_terms[index], semantic_query_terms[row[\"query-id\"] - 1]))\n",
        "    res['name'].append('STANDARD')\n",
        "\n",
        "df_res = pd.DataFrame.from_dict(res)\n",
        "\n",
        "df_res.to_csv(filename + '_late_sum.txt', sep=' ', index=False, header=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vtbHxS8F0-r",
        "colab_type": "text"
      },
      "source": [
        "# Late max"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fNVYjyVGQJ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "raw = pd.read_csv(r'qrels.txt', delimiter='\\t', names=[\"query-id\", \"zeros\", \"table-id\", \"rel\"])\n",
        "\n",
        "res = {\n",
        "    'query-id': list(),\n",
        "    'q0': list(),\n",
        "    'document-id': list(),\n",
        "    'rank': list(),\n",
        "    'score': list(),\n",
        "    'name': list()\n",
        "}\n",
        "\n",
        "for index, row in raw.iterrows():\n",
        "    res['query-id'].append(row[\"query-id\"])\n",
        "    res['q0'].append('Q0')\n",
        "    res['document-id'].append(row[\"table-id\"])\n",
        "    res['rank'].append(0)\n",
        "    res['score'].append(cos_late_max_sim(semantic_table_terms[index], semantic_query_terms[row[\"query-id\"] - 1]))\n",
        "    res['name'].append('STANDARD')\n",
        "\n",
        "df_res = pd.DataFrame.from_dict(res)\n",
        "\n",
        "df_res.to_csv(filename + '_late_max.txt', sep=' ', index=False, header=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mk_jXqrGPeUI",
        "colab_type": "text"
      },
      "source": [
        "# Early"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ve8ZIKxSPd6r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "raw = pd.read_csv(r'qrels.txt', delimiter='\\t', names=[\"query-id\", \"zeros\", \"table-id\", \"rel\"])\n",
        "\n",
        "res = {\n",
        "    'query-id': list(),\n",
        "    'q0': list(),\n",
        "    'document-id': list(),\n",
        "    'rank': list(),\n",
        "    'score': list(),\n",
        "    'name': list()\n",
        "}\n",
        "\n",
        "for index, row in raw.iterrows():\n",
        "    res['query-id'].append(row[\"query-id\"])\n",
        "    res['q0'].append('Q0')\n",
        "    res['document-id'].append(row[\"table-id\"])\n",
        "    res['rank'].append(0)\n",
        "    res['score'].append(cos_early_sim(semantic_table_terms[index], table_terms[index], semantic_query_terms[row[\"query-id\"] - 1], query_terms[row[\"query-id\"] - 1]))\n",
        "    res['name'].append('STANDARD')\n",
        "\n",
        "df_res = pd.DataFrame.from_dict(res)\n",
        "\n",
        "df_res.to_csv(filename + '_early.txt', sep=' ', index=False, header=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}