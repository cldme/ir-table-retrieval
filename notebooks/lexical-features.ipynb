{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lexical Features (table-retrieval LTR baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = pd.read_json(r'data/tables/re_tables-0875.json')\n",
    "features = pd.read_csv(r'data/features/features.txt')\n",
    "qrels = pd.read_csv(r'data/queries/qrels.txt', sep='\\t', header=None)\n",
    "queries = pd.read_csv(r'data/queries/queries.txt', header=None)\n",
    "queries = pd.DataFrame([row[0][row[0].find(' ') + 1:] for index, row in queries.iterrows()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of stop words from nltk english corpus\n",
    "sw = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>query</th>\n",
       "      <th>table_id</th>\n",
       "      <th>row</th>\n",
       "      <th>col</th>\n",
       "      <th>nul</th>\n",
       "      <th>in_link</th>\n",
       "      <th>out_link</th>\n",
       "      <th>pgcount</th>\n",
       "      <th>tImp</th>\n",
       "      <th>...</th>\n",
       "      <th>cmax</th>\n",
       "      <th>csum</th>\n",
       "      <th>cavg</th>\n",
       "      <th>csim</th>\n",
       "      <th>remax</th>\n",
       "      <th>resum</th>\n",
       "      <th>reavg</th>\n",
       "      <th>resim</th>\n",
       "      <th>query_l</th>\n",
       "      <th>rel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>world interest rates Table</td>\n",
       "      <td>table-0875-680</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>21</td>\n",
       "      <td>51438</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>5.291894</td>\n",
       "      <td>0.048108</td>\n",
       "      <td>0.354686</td>\n",
       "      <td>0.241209</td>\n",
       "      <td>3.716354</td>\n",
       "      <td>0.033785</td>\n",
       "      <td>0.281130</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>world interest rates Table</td>\n",
       "      <td>table-1020-619</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>324</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.116121</td>\n",
       "      <td>0.101056</td>\n",
       "      <td>0.718895</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.075247</td>\n",
       "      <td>0.073411</td>\n",
       "      <td>0.710250</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>world interest rates Table</td>\n",
       "      <td>table-0288-531</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>26419</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067373</td>\n",
       "      <td>0.365818</td>\n",
       "      <td>0.003326</td>\n",
       "      <td>0.033680</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>world interest rates Table</td>\n",
       "      <td>table-0288-530</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>26419</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067373</td>\n",
       "      <td>0.365818</td>\n",
       "      <td>0.003326</td>\n",
       "      <td>0.033680</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>world interest rates Table</td>\n",
       "      <td>table-1000-57</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>2268</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.147388</td>\n",
       "      <td>0.092249</td>\n",
       "      <td>0.372667</td>\n",
       "      <td>0.226134</td>\n",
       "      <td>4.564622</td>\n",
       "      <td>0.041497</td>\n",
       "      <td>0.279899</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id                       query        table_id  row  col  nul  \\\n",
       "0         1  world interest rates Table  table-0875-680    8    2    0   \n",
       "1         1  world interest rates Table  table-1020-619    4    3    0   \n",
       "2         1  world interest rates Table  table-0288-531    3    5    0   \n",
       "3         1  world interest rates Table  table-0288-530    4    5    1   \n",
       "4         1  world interest rates Table   table-1000-57    2    2    0   \n",
       "\n",
       "   in_link  out_link  pgcount  tImp  ...      cmax       csum      cavg  \\\n",
       "0       31        21    51438   1.0  ...  0.666667   5.291894  0.048108   \n",
       "1       18         0      324   1.0  ...  1.000000  11.116121  0.101056   \n",
       "2       23        22    26419   0.5  ...  0.000000   0.000000  0.000000   \n",
       "3       23        22    26419   0.5  ...  0.000000   0.000000  0.000000   \n",
       "4       38         1     2268   1.0  ...  1.000000  10.147388  0.092249   \n",
       "\n",
       "       csim     remax     resum     reavg     resim  query_l  rel  \n",
       "0  0.354686  0.241209  3.716354  0.033785  0.281130        4    0  \n",
       "1  0.718895  1.000000  8.075247  0.073411  0.710250        4    0  \n",
       "2  0.000000  0.067373  0.365818  0.003326  0.033680        4    0  \n",
       "3  0.000000  0.067373  0.365818  0.003326  0.033680        4    0  \n",
       "4  0.372667  0.226134  4.564622  0.041497  0.279899        4    0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_id                                  1\n",
      "query            world interest rates Table\n",
      "table_id                     table-0875-680\n",
      "row                                       8\n",
      "col                                       2\n",
      "nul                                       0\n",
      "in_link                                  31\n",
      "out_link                                 21\n",
      "pgcount                               51438\n",
      "tImp                                      1\n",
      "tPF                             0.000259799\n",
      "leftColhits                               0\n",
      "SecColhits                                0\n",
      "bodyhits                                  0\n",
      "PMI                                       0\n",
      "qInPgTitle                         0.333333\n",
      "qInTableTitle                      0.222222\n",
      "yRank                                   100\n",
      "csr_score                       7.46742e-10\n",
      "idf1                                29.6279\n",
      "idf2                                24.1356\n",
      "idf3                                27.1006\n",
      "idf4                                31.2193\n",
      "idf5                                27.3592\n",
      "idf6                                27.1006\n",
      "max                                       1\n",
      "sum                                 9.26618\n",
      "avg                                0.110312\n",
      "sim                                0.676819\n",
      "emax                               0.952804\n",
      "esum                                89.7071\n",
      "eavg                               0.815519\n",
      "esim                               0.971854\n",
      "cmax                               0.666667\n",
      "csum                                5.29189\n",
      "cavg                              0.0481081\n",
      "csim                               0.354686\n",
      "remax                              0.241209\n",
      "resum                               3.71635\n",
      "reavg                              0.033785\n",
      "resim                               0.28113\n",
      "query_l                                   4\n",
      "rel                                       0\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(features.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save table ids for later use\n",
    "table_ids = features['table_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encode the data using pandas get_dummies\n",
    "features = pd.get_dummies(features, columns = ['table_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.drop(['query', 'max', 'sum', 'avg', 'sim', 'emax', 'esum', 'eavg', 'esim', 'cmax', 'csum', 'cavg', 'csim', 'remax', 'resum', 'reavg', 'resim'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract labels from features (labels are the values we want to predict)\n",
    "labels = np.array(features['rel'])\n",
    "\n",
    "# remove labels from features\n",
    "features.drop(['rel'], axis = 1, inplace = True)\n",
    "\n",
    "# save feature names for later use\n",
    "feature_columns = list(features.columns)\n",
    "\n",
    "# convert features to numpy array\n",
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape: (2340, 2956)\n",
      "Training Labels Shape: (2340,)\n",
      "Testing Features Shape: (780, 2956)\n",
      "Testing Labels Shape: (780,)\n"
     ]
    }
   ],
   "source": [
    "print(f'Training Features Shape: {train_features.shape}')\n",
    "print(f'Training Labels Shape: {train_labels.shape}')\n",
    "print(f'Testing Features Shape: {test_features.shape}')\n",
    "print(f'Testing Labels Shape: {test_labels.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training (random forests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "\n",
    "# train the model on training data\n",
    "rf.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save model to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "dump(rf, 'random_forest.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load model from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "rf = load('random_forest.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean square error  : 0.18987227435897439\n",
      "mean absolute error: 0.22587692307692311\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "predictions = rf.predict(test_features)\n",
    "print(f'mean square error  : {metrics.mean_squared_error(test_labels, predictions)}')\n",
    "print(f'mean absolute error: {metrics.mean_absolute_error(test_labels, predictions)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean square error  : 0.06934630448717949\n",
      "mean absolute error: 0.1244096153846154\n"
     ]
    }
   ],
   "source": [
    "predictions_all = rf.predict(features)\n",
    "print(f'mean square error  : {metrics.mean_squared_error(labels, predictions_all)}')\n",
    "print(f'mean absolute error: {metrics.mean_absolute_error(labels, predictions_all)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate results in trec_eval format\n",
    "raw = pd.read_csv(r'data/features/features.txt')\n",
    "res = {\n",
    "    'query-id': list(),\n",
    "    'q0': list(),\n",
    "    'document-id': list(),\n",
    "    'rank': list(),\n",
    "    'score': list(),\n",
    "    'name': list()\n",
    "}\n",
    "\n",
    "for index, row in raw.iterrows():\n",
    "    res['query-id'].append(row['query_id'])\n",
    "    res['q0'].append('Q0')\n",
    "    res['document-id'].append(row['table_id'])\n",
    "    res['rank'].append(0)\n",
    "    res['score'].append(predictions_all[index])\n",
    "    res['name'].append('STANDARD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pd.DataFrame.from_dict(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query-id</th>\n",
       "      <th>q0</th>\n",
       "      <th>document-id</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Q0</td>\n",
       "      <td>table-0875-680</td>\n",
       "      <td>0</td>\n",
       "      <td>0.020</td>\n",
       "      <td>STANDARD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Q0</td>\n",
       "      <td>table-1020-619</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>STANDARD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Q0</td>\n",
       "      <td>table-0288-531</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004</td>\n",
       "      <td>STANDARD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Q0</td>\n",
       "      <td>table-0288-530</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>STANDARD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Q0</td>\n",
       "      <td>table-1000-57</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>STANDARD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query-id  q0     document-id  rank  score      name\n",
       "0         1  Q0  table-0875-680     0  0.020  STANDARD\n",
       "1         1  Q0  table-1020-619     0  0.002  STANDARD\n",
       "2         1  Q0  table-0288-531     0  0.004  STANDARD\n",
       "3         1  Q0  table-0288-530     0  0.002  STANDARD\n",
       "4         1  Q0   table-1000-57     0  0.002  STANDARD"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results to .txt file (for running trec_eval comparison)\n",
    "df_res.to_csv('results.txt', sep=' ', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QLEN\n",
    "def get_qlen(query):\n",
    "    return len(query.split(' '))\n",
    "\n",
    "# IDF\n",
    "def get_idf(query, field):\n",
    "    # instantiate count vectorizer\n",
    "    cv=CountVectorizer(field, stop_words=sw)\n",
    "    # this steps generates word counts for the words in your docs\n",
    "    word_count_vector=cv.fit_transform(field)\n",
    "    # instantiate tfidf transformer (with use_idf true in order to compute idf scores)\n",
    "    tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
    "    # compute the idf scores\n",
    "    tfidf_transformer.fit(word_count_vector)\n",
    "    # compute the sum of idf scores for all query terms\n",
    "    score = sum([tfidf_transformer.idf_[cv.get_feature_names().index(term)] for term in query.split(' ')])\n",
    "    # return idf score\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lexical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lexical_features(entries):\n",
    "    res = list()\n",
    "    for entry in entries:\n",
    "        features = list()\n",
    "        # QLEN\n",
    "        features.append(entry[41])\n",
    "        # IDF scores\n",
    "        features.append(entry[19])\n",
    "        features.append(entry[20])\n",
    "        features.append(entry[21])\n",
    "        features.append(entry[22])\n",
    "        features.append(entry[23])\n",
    "        features.append(entry[24])\n",
    "        # number of rows\n",
    "        features.append(entry[3])\n",
    "        # number of columns\n",
    "        features.append(entry[4])\n",
    "        # number of empty cells\n",
    "        features.append(entry[5])\n",
    "        # PMI\n",
    "        features.append(entry[14])\n",
    "        # number of in-links\n",
    "        features.append(entry[6])\n",
    "        # number of out-links\n",
    "        features.append(entry[7])\n",
    "        # number of page views\n",
    "        features.append(entry[8])\n",
    "        # table importance\n",
    "        features.append(entry[9])\n",
    "        # table page fraction\n",
    "        features.append(entry[10])\n",
    "        # hits left column\n",
    "        features.append(entry[11])\n",
    "        # hits second to left column\n",
    "        features.append(entry[12])\n",
    "        # hits body\n",
    "        features.append(entry[13])\n",
    "        # ratio of query tokens found in page title\n",
    "        features.append(entry[15])\n",
    "        # ratio of query tokens found in table title\n",
    "        features.append(entry[16])\n",
    "        # y-rank\n",
    "        features.append(entry[17])\n",
    "        # mlm similarity\n",
    "        features.append(entry[28])\n",
    "        # add features to results list\n",
    "        res.append(features)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bigjson.bigjson as bj\n",
    "\n",
    "with open('data/tables.json', 'rb') as f:\n",
    "    reader = bj.FileReader(f, 'utf-8')\n",
    "    i = reader.read(True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(i.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/tableMentions.json', 'rb') as f:\n",
    "    reader = bj.FileReader(f, 'utf-8')\n",
    "    j = reader.read(True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(j.items())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
