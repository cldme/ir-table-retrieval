{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Coco\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = pd.read_json(r'data/tables/re_tables-0875.json')\n",
    "features = pd.read_csv(r'data/features/features.txt')\n",
    "qrels = pd.read_csv(r'data/queries/qrels.txt', sep='\\t', header=None)\n",
    "queries = pd.read_csv(r'data/queries/queries.txt', header=None)\n",
    "queries = pd.DataFrame([row[0][row[0].find(' ') + 1:] for index, row in queries.iterrows()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of stop words from nltk english corpus\n",
    "sw = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_id                                  1\n",
      "query            world interest rates Table\n",
      "table_id                     table-0875-680\n",
      "row                                       8\n",
      "col                                       2\n",
      "nul                                       0\n",
      "in_link                                  31\n",
      "out_link                                 21\n",
      "pgcount                               51438\n",
      "tImp                                      1\n",
      "tPF                             0.000259799\n",
      "leftColhits                               0\n",
      "SecColhits                                0\n",
      "bodyhits                                  0\n",
      "PMI                                       0\n",
      "qInPgTitle                         0.333333\n",
      "qInTableTitle                      0.222222\n",
      "yRank                                   100\n",
      "csr_score                       7.46742e-10\n",
      "idf1                                29.6279\n",
      "idf2                                24.1356\n",
      "idf3                                27.1006\n",
      "idf4                                31.2193\n",
      "idf5                                27.3592\n",
      "idf6                                27.1006\n",
      "max                                       1\n",
      "sum                                 9.26618\n",
      "avg                                0.110312\n",
      "sim                                0.676819\n",
      "emax                               0.952804\n",
      "esum                                89.7071\n",
      "eavg                               0.815519\n",
      "esim                               0.971854\n",
      "cmax                               0.666667\n",
      "csum                                5.29189\n",
      "cavg                              0.0481081\n",
      "csim                               0.354686\n",
      "remax                              0.241209\n",
      "resum                               3.71635\n",
      "reavg                              0.033785\n",
      "resim                               0.28113\n",
      "query_l                                   4\n",
      "rel                                       0\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(features.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QLEN\n",
    "def get_qlen(query):\n",
    "    return len(query.split(' '))\n",
    "\n",
    "# IDF\n",
    "def get_idf(query, field):\n",
    "    # instantiate count vectorizer\n",
    "    cv=CountVectorizer(field, stop_words=sw)\n",
    "    # this steps generates word counts for the words in your docs\n",
    "    word_count_vector=cv.fit_transform(field)\n",
    "    # instantiate tfidf transformer (with use_idf true in order to compute idf scores)\n",
    "    tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
    "    # compute the idf scores\n",
    "    tfidf_transformer.fit(word_count_vector)\n",
    "    # compute the sum of idf scores for all query terms\n",
    "    score = sum([tfidf_transformer.idf_[cv.get_feature_names().index(term)] for term in query.split(' ')])\n",
    "    # return idf score\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lexical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lexical_features(entries):\n",
    "    res = list()\n",
    "    for entry in entries:\n",
    "        features = list()\n",
    "        # QLEN\n",
    "        features.append(entry[41])\n",
    "        # IDF scores\n",
    "        features.append(entry[19])\n",
    "        features.append(entry[20])\n",
    "        features.append(entry[21])\n",
    "        features.append(entry[22])\n",
    "        features.append(entry[23])\n",
    "        features.append(entry[24])\n",
    "        # number of rows\n",
    "        features.append(entry[3])\n",
    "        # number of columns\n",
    "        features.append(entry[4])\n",
    "        # number of empty cells\n",
    "        features.append(entry[5])\n",
    "        # PMI\n",
    "        features.append(entry[14])\n",
    "        # number of in-links\n",
    "        features.append(entry[6])\n",
    "        # number of out-links\n",
    "        features.append(entry[7])\n",
    "        # number of page views\n",
    "        features.append(entry[8])\n",
    "        # table importance\n",
    "        features.append(entry[9])\n",
    "        # table page fraction\n",
    "        features.append(entry[10])\n",
    "        # hits left column\n",
    "        features.append(entry[11])\n",
    "        # hits second to left column\n",
    "        features.append(entry[12])\n",
    "        # hits body\n",
    "        features.append(entry[13])\n",
    "        # ratio of query tokens found in page title\n",
    "        features.append(entry[15])\n",
    "        # ratio of query tokens found in table title\n",
    "        features.append(entry[16])\n",
    "        # y-rank\n",
    "        features.append(entry[17])\n",
    "        # mlm similarity\n",
    "        features.append(entry[28])\n",
    "        # add features to results list\n",
    "        res.append(features)\n",
    "    return res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
