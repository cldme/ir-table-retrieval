{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lexical Features (table-retrieval LTR baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = pd.read_json(r'data/tables/re_tables-0875.json')\n",
    "features = pd.read_csv(r'data/features/features.txt')\n",
    "qrels = pd.read_csv(r'data/queries/qrels.txt', sep='\\t', header=None)\n",
    "queries = pd.read_csv(r'data/queries/queries.txt', header=None)\n",
    "queries = pd.DataFrame([row[0][row[0].find(' ') + 1:] for index, row in queries.iterrows()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of stop words from nltk english corpus\n",
    "sw = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>query</th>\n",
       "      <th>table_id</th>\n",
       "      <th>row</th>\n",
       "      <th>col</th>\n",
       "      <th>nul</th>\n",
       "      <th>in_link</th>\n",
       "      <th>out_link</th>\n",
       "      <th>pgcount</th>\n",
       "      <th>tImp</th>\n",
       "      <th>...</th>\n",
       "      <th>cmax</th>\n",
       "      <th>csum</th>\n",
       "      <th>cavg</th>\n",
       "      <th>csim</th>\n",
       "      <th>remax</th>\n",
       "      <th>resum</th>\n",
       "      <th>reavg</th>\n",
       "      <th>resim</th>\n",
       "      <th>query_l</th>\n",
       "      <th>rel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>world interest rates Table</td>\n",
       "      <td>table-0875-680</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>21</td>\n",
       "      <td>51438</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>5.291894</td>\n",
       "      <td>0.048108</td>\n",
       "      <td>0.354686</td>\n",
       "      <td>0.241209</td>\n",
       "      <td>3.716354</td>\n",
       "      <td>0.033785</td>\n",
       "      <td>0.281130</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>world interest rates Table</td>\n",
       "      <td>table-1020-619</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>324</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.116121</td>\n",
       "      <td>0.101056</td>\n",
       "      <td>0.718895</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.075247</td>\n",
       "      <td>0.073411</td>\n",
       "      <td>0.710250</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>world interest rates Table</td>\n",
       "      <td>table-0288-531</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>26419</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067373</td>\n",
       "      <td>0.365818</td>\n",
       "      <td>0.003326</td>\n",
       "      <td>0.033680</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>world interest rates Table</td>\n",
       "      <td>table-0288-530</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>26419</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067373</td>\n",
       "      <td>0.365818</td>\n",
       "      <td>0.003326</td>\n",
       "      <td>0.033680</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>world interest rates Table</td>\n",
       "      <td>table-1000-57</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>2268</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.147388</td>\n",
       "      <td>0.092249</td>\n",
       "      <td>0.372667</td>\n",
       "      <td>0.226134</td>\n",
       "      <td>4.564622</td>\n",
       "      <td>0.041497</td>\n",
       "      <td>0.279899</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id                       query        table_id  row  col  nul  \\\n",
       "0         1  world interest rates Table  table-0875-680    8    2    0   \n",
       "1         1  world interest rates Table  table-1020-619    4    3    0   \n",
       "2         1  world interest rates Table  table-0288-531    3    5    0   \n",
       "3         1  world interest rates Table  table-0288-530    4    5    1   \n",
       "4         1  world interest rates Table   table-1000-57    2    2    0   \n",
       "\n",
       "   in_link  out_link  pgcount  tImp  ...      cmax       csum      cavg  \\\n",
       "0       31        21    51438   1.0  ...  0.666667   5.291894  0.048108   \n",
       "1       18         0      324   1.0  ...  1.000000  11.116121  0.101056   \n",
       "2       23        22    26419   0.5  ...  0.000000   0.000000  0.000000   \n",
       "3       23        22    26419   0.5  ...  0.000000   0.000000  0.000000   \n",
       "4       38         1     2268   1.0  ...  1.000000  10.147388  0.092249   \n",
       "\n",
       "       csim     remax     resum     reavg     resim  query_l  rel  \n",
       "0  0.354686  0.241209  3.716354  0.033785  0.281130        4    0  \n",
       "1  0.718895  1.000000  8.075247  0.073411  0.710250        4    0  \n",
       "2  0.000000  0.067373  0.365818  0.003326  0.033680        4    0  \n",
       "3  0.000000  0.067373  0.365818  0.003326  0.033680        4    0  \n",
       "4  0.372667  0.226134  4.564622  0.041497  0.279899        4    0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_id                                  1\n",
      "query            world interest rates Table\n",
      "table_id                     table-1020-619\n",
      "row                                       4\n",
      "col                                       3\n",
      "nul                                       0\n",
      "in_link                                  18\n",
      "out_link                                  0\n",
      "pgcount                                 324\n",
      "tImp                                      1\n",
      "tPF                             0.000786473\n",
      "leftColhits                               0\n",
      "SecColhits                                0\n",
      "bodyhits                                  0\n",
      "PMI                               -0.231049\n",
      "qInPgTitle                                0\n",
      "qInTableTitle                      0.285714\n",
      "yRank                                   100\n",
      "csr_score                       8.66373e-10\n",
      "idf1                                29.6279\n",
      "idf2                                24.1356\n",
      "idf3                                27.1006\n",
      "idf4                                31.2193\n",
      "idf5                                27.3592\n",
      "idf6                                27.1006\n",
      "max                                       1\n",
      "sum                                 3.03827\n",
      "avg                                 0.10851\n",
      "sim                                0.863125\n",
      "emax                                      1\n",
      "esum                                83.3752\n",
      "eavg                               0.757956\n",
      "esim                               0.983893\n",
      "cmax                                      1\n",
      "csum                                11.1161\n",
      "cavg                               0.101056\n",
      "csim                               0.718895\n",
      "remax                                     1\n",
      "resum                               8.07525\n",
      "reavg                             0.0734113\n",
      "resim                               0.71025\n",
      "query_l                                   4\n",
      "rel                                       0\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(features.iloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save table ids for later use\n",
    "table_ids = features['table_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encode the data using pandas get_dummies\n",
    "features = pd.get_dummies(features, columns = ['table_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.drop(['query', 'max', 'sum', 'avg', 'sim', 'emax', 'esum', 'eavg', 'esim', 'cmax', 'csum', 'cavg', 'csim', 'remax', 'resum', 'reavg', 'resim'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract labels from features (labels are the values we want to predict)\n",
    "labels = np.array(features['rel'])\n",
    "\n",
    "# remove labels from features\n",
    "features.drop(['rel'], axis = 1, inplace = True)\n",
    "\n",
    "# save feature names for later use\n",
    "feature_columns = list(features.columns)\n",
    "\n",
    "# convert features to numpy array\n",
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape: (2496, 2956)\n",
      "Training Labels Shape: (2496,)\n",
      "Testing Features Shape: (624, 2956)\n",
      "Testing Labels Shape: (624,)\n"
     ]
    }
   ],
   "source": [
    "print(f'Training Features Shape: {train_features.shape}')\n",
    "print(f'Training Labels Shape: {train_labels.shape}')\n",
    "print(f'Testing Features Shape: {test_features.shape}')\n",
    "print(f'Testing Labels Shape: {test_labels.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training (random forests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 1000, max_depth=3, n_jobs = 10, random_state = 42)\n",
    "\n",
    "# train the model on training data\n",
    "rf.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save model to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "# random_forest_1000_none.joblib: n_estimators = 1000, max_depth = None\n",
    "# random_forest_1000_3.joblib: n_estimators = 1000, max_depth = 3\n",
    "dump(rf, 'random_forest_1000_3.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load model from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "rf = load('random_forest.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    errors = abs(predictions - test_labels)\n",
    "    mape = 100 * np.mean(errors / test_labels)\n",
    "    accuracy = 100 - mape\n",
    "    print('Model Performance')\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# create the parameter grid\n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [3, 5, None],\n",
    "    'n_estimators': [100, 500, 1000, 1500, 2000]\n",
    "}\n",
    "\n",
    "# create a based model\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, cv = 5, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the grid search to the data\n",
    "grid_search.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "predictions = rf.predict(test_features)\n",
    "print(f'mean square error  : {metrics.mean_squared_error(test_labels, predictions)}')\n",
    "print(f'mean absolute error: {metrics.mean_absolute_error(test_labels, predictions)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rf.predict(features)\n",
    "print(f'mean square error  : {metrics.mean_squared_error(labels, predictions)}')\n",
    "print(f'mean absolute error: {metrics.mean_absolute_error(labels, predictions)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate results in trec_eval format\n",
    "raw = pd.read_csv(r'data/features/features.txt')\n",
    "res = {\n",
    "    'query-id': list(),\n",
    "    'q0': list(),\n",
    "    'document-id': list(),\n",
    "    'rank': list(),\n",
    "    'score': list(),\n",
    "    'name': list()\n",
    "}\n",
    "\n",
    "for index, row in raw.iterrows():\n",
    "    res['query-id'].append(row['query_id'])\n",
    "    res['q0'].append('Q0')\n",
    "    res['document-id'].append(row['table_id'])\n",
    "    res['rank'].append(0)\n",
    "    res['score'].append(predictions[index])\n",
    "    res['name'].append('STANDARD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pd.DataFrame.from_dict(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results to .txt file (for running trec_eval comparison)\n",
    "df_res.to_csv('results_1000_3.txt', sep=' ', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# QLEN\n",
    "def get_qlen(query):\n",
    "    return len(query.split(' '))\n",
    "\n",
    "# IDF\n",
    "def get_idf(query, field):\n",
    "    # instantiate count vectorizer\n",
    "    cv=CountVectorizer(field, stop_words=sw)\n",
    "    # this steps generates word counts for the words in your docs\n",
    "    word_count_vector=cv.fit_transform(field)\n",
    "    # instantiate tfidf transformer (with use_idf true in order to compute idf scores)\n",
    "    tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
    "    # compute the idf scores\n",
    "    tfidf_transformer.fit(word_count_vector)\n",
    "    # compute the sum of idf scores for all query terms\n",
    "    score = sum([tfidf_transformer.idf_[cv.get_feature_names().index(term)] for term in query.split(' ')])\n",
    "    # return idf score\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lexical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import wikipediaapi\n",
    "import pageviewapi.period\n",
    "from wikitables import import_tables\n",
    "logging.getLogger('wikitables').setLevel(logging.ERROR)\n",
    "\n",
    "wiki = wikipediaapi.Wikipedia('en')\n",
    "\n",
    "for i in range(1, 1001):\n",
    "    print(f'processing file {i}')\n",
    "    prefix = '0' * (4 - len(str(i)))\n",
    "    file = prefix + str(i)\n",
    "    out_features = 'data/features/table-features-' + file + '.txt'\n",
    "    table = 'data/tables/re_tables-' + file +'.json'\n",
    "    tmp = pd.read_json(table)\n",
    "    tmpT = tmp.T\n",
    "    \n",
    "    fields = {\n",
    "        'page_titles': set(),\n",
    "        'section_titles': set(),\n",
    "        'table_captions': set(),\n",
    "        'table_bodies': set()\n",
    "    }\n",
    "    \n",
    "    features = {\n",
    "        'table_id': list(),\n",
    "        'rows': list(),\n",
    "        'cols': list(),\n",
    "        'nulls': list(),\n",
    "        'inlinks': list(),\n",
    "        'outlinks': list(),\n",
    "        'views': list(),\n",
    "        'table_imp': list(),\n",
    "        'table_fraction': list()\n",
    "    }\n",
    "    \n",
    "    i = 0\n",
    "    for index, row in tmpT.iterrows():\n",
    "        table_id = tmp.iloc[0].index[i]\n",
    "        rows = row['numDataRows']\n",
    "        cols = row['numCols']\n",
    "        title = row['pgTitle']\n",
    "        caption = row['caption']\n",
    "        data = row['data']\n",
    "        section_title = [item.lower() for item in row['title']]\n",
    "        fields['section_titles'].update(section_title)\n",
    "        \n",
    "        inlinks = 0; outlinks = 0; views = 0; table_imp = 0; text_len = 0; chars = 0; nulls = 0; page_tables = 0\n",
    "        \n",
    "        for entry in data:\n",
    "            for item in entry:\n",
    "                fields['table_bodies'].update({item.lower()})\n",
    "                if len(item) == 0:\n",
    "                    nulls += 1\n",
    "                chars += len(item)\n",
    "                \n",
    "        page = wiki.page(title)\n",
    "        if page.exists():\n",
    "            inlinks = len(page.backlinks)\n",
    "            outlinks = len(page.links)\n",
    "            try:\n",
    "                views = pageviewapi.period.sum_last('en.wikipedia', title, last=365, access='all-access', agent='all-agents')\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                page_tables = len(import_tables(title))\n",
    "            except:\n",
    "                pass\n",
    "            table_imp = 1 / (page_tables + 1)\n",
    "            text_len = len(page.text)\n",
    "        \n",
    "        table_fraction = chars / (text_len + 1)\n",
    "        \n",
    "        fields['page_titles'].update({title.lower()})\n",
    "        fields['table_captions'].update({caption.lower()})\n",
    "        \n",
    "        features['table_id'].append(table_id)\n",
    "        features['rows'].append(rows)\n",
    "        features['cols'].append(cols)\n",
    "        features['nulls'].append(nulls)\n",
    "        features['inlinks'].append(inlinks)\n",
    "        features['outlinks'].append(outlinks)\n",
    "        features['views'].append(views)\n",
    "        features['table_imp'].append(table_imp)\n",
    "        features['table_fraction'].append(table_fraction)\n",
    "        i += 1\n",
    "        if i % 100 == 0:\n",
    "            print(f'done processing {i} tables!')\n",
    "    df_features = pd.DataFrame.from_dict(features)\n",
    "    df_features.to_csv(out_features, sep=' ', index=False, header=True)\n",
    "    \n",
    "    out_fields = 'data/fields/page_titles/table-fields-' + file + '.txt'\n",
    "    df_fields = pd.DataFrame.from_dict(fields['page_titles'])\n",
    "    df_fields.to_csv(out_fields, sep=' ', index=False, header=True)\n",
    "    \n",
    "    out_fields = 'data/fields/section_titles/table-fields-' + file + '.txt'\n",
    "    df_fields = pd.DataFrame.from_dict(fields['section_titles'])\n",
    "    df_fields.to_csv(out_fields, sep=' ', index=False, header=True)\n",
    "    \n",
    "    out_fields = 'data/fields/table_captions/table-fields-' + file + '.txt'\n",
    "    df_fields = pd.DataFrame.from_dict(fields['table_captions'])\n",
    "    df_fields.to_csv(out_fields, sep=' ', index=False, header=True)\n",
    "    \n",
    "    out_fields = 'data/fields/table_bodies/table-fields-' + file + '.txt'\n",
    "    df_fields = pd.DataFrame.from_dict(fields['table_bodies'])\n",
    "    df_fields.to_csv(out_fields, sep=' ', index=False, header=True)\n",
    "    \n",
    "    print(f'done processing file {i}')\n",
    "print(f'done processing all tables!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = pd.DataFrame.from_dict(features)\n",
    "df_features.to_csv('table-features-1.txt', sep=' ', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features)\n",
    "print(page_titles)\n",
    "print(section_titles)\n",
    "print(table_captions)\n",
    "print(table_bodies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bigjson.bigjson as bj\n",
    "\n",
    "with open('tables.json', 'rb') as f:\n",
    "    reader = bj.FileReader(f, 'utf-8')\n",
    "    i = reader.read(True, False)\n",
    "    \n",
    "print(i.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tableMentions.json', 'rb') as f:\n",
    "    reader = bj.FileReader(f, 'utf-8')\n",
    "    j = reader.read(True, True)\n",
    "    \n",
    "print(j.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the data frames on top of each other\n",
    "# vertical_stack = pd.concat([df_1, df_2], axis=0)\n",
    "# newtmp = tmp.set_index('table_id').T.to_dict('list')\n",
    "# tmp1 = pd.DataFrame.from_dict(newtmp).T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
